{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "..\\..\\..\\modules\\python\\src2\\cv2.cpp:163: error: (-215) The data should normally be NULL! in function NumpyAllocator::allocate\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f2c4006af620>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mkp_grayframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc_grayframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrayframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mmatches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mknnMatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdesc_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc_grayframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mgood_points\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: ..\\..\\..\\modules\\python\\src2\\cv2.cpp:163: error: (-215) The data should normally be NULL! in function NumpyAllocator::allocate\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "img = cv2.imread(\"goalkeeper.jpg\", cv2.IMREAD_GRAYSCALE) # queryiamge\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "# Features\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp_image, desc_image = sift.detectAndCompute(img, None)\n",
    " \n",
    "# Feature matching\n",
    "index_params = dict(algorithm=0, trees=5)\n",
    "search_params = dict()\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    " \n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # trainimage\n",
    " \n",
    "    kp_grayframe, desc_grayframe = sift.detectAndCompute(grayframe, None)\n",
    "    matches = flann.knnMatch(desc_image, desc_grayframe, k=2)\n",
    " \n",
    "    good_points = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.6*n.distance:\n",
    "            good_points.append(m)\n",
    " \n",
    "    #img3 = cv2.drawMatches(img, kp_image, grayframe, kp_grayframe, good_points, grayframe)\n",
    " \n",
    "    # Homography\n",
    "    if len(good_points) > 10:\n",
    "        query_pts = np.float32([kp_image[m.queryIdx].pt for m in good_points]).reshape(-1, 1, 2)\n",
    "        train_pts = np.float32([kp_grayframe[m.trainIdx].pt for m in good_points]).reshape(-1, 1, 2)\n",
    " \n",
    "        matrix, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0)\n",
    "        matches_mask = mask.ravel().tolist()\n",
    " \n",
    "        # Perspective transform\n",
    "        h, w = img.shape\n",
    "        pts = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "        dst = cv2.perspectiveTransform(pts, matrix)\n",
    " \n",
    "        homography = cv2.polylines(frame, [np.int32(dst)], True, (255, 0, 0), 3)\n",
    " \n",
    "        cv2.imshow(\"Homography\", homography)\n",
    "    else:\n",
    "        cv2.imshow(\"Homography\", grayframe)\n",
    " \n",
    " \n",
    " \n",
    "    #cv2.imshow(\"Image\", img)\n",
    "    #cv2.imshow(\"grayFrame\", grayframe)\n",
    "    #cv2.imshow(\"img3\", img3)\n",
    " \n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:opencv3]",
   "language": "python",
   "name": "conda-env-opencv3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
